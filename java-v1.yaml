tep 1: Create the project
Run the Maven command:
bashcd C:\devhome\projects\Flink-POC

mvn archetype:generate ^
  -DarchetypeGroupId=org.apache.flink ^
  -DarchetypeArtifactId=flink-quickstart-java ^
  -DarchetypeVersion=1.18.1 ^
  -DgroupId=com.poc.flink ^
  -DartifactId=flink-sample-app ^
  -Dversion=1.0-SNAPSHOT ^
  -DinteractiveMode=false
Step 2: Replace the default code
Once created, open flink-sample-app/src/main/java/com/poc/flink/DataStreamJob.java and replace it with this simple app:
javapackage com.poc.flink;

import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.functions.source.SourceFunction;

public class DataStreamJob {

    public static void main(String[] args) throws Exception {
        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        // Simple source that generates sample data
        DataStream<String> stream = env.addSource(new SourceFunction<String>() {
            private volatile boolean running = true;

            @Override
            public void run(SourceContext<String> ctx) throws Exception {
                long count = 0;
                while (running) {
                    ctx.collect("Transaction-" + count + " | Amount: " + (Math.random() * 1000));
                    count++;
                    Thread.sleep(1000); // emit every 1 second
                }
            }

            @Override
            public void cancel() {
                running = false;
            }
        });

        stream.map(value -> "Processed: " + value)
              .print();

        env.execute("Flink Sample POC");
    }
}
This app simply generates fake transactions every second and logs them — enough to prove the setup works.
Step 3: Build the JAR
bashcd flink-sample-app
mvn clean package -DskipTests
The JAR will be at: target/flink-sample-app-1.0-SNAPSHOT.jar
Step 4: Deploy to AWS Managed Flink

Upload the JAR to an S3 bucket in your AWS account
Go to Amazon Managed Apache Flink in the console
Click Create Application
Set runtime to Apache Flink 1.18
Point to your S3 JAR location
For the IAM role — use the one your admin pre-created (from our earlier discussion)
Click Create and then Run

































AWSTemplateFormatVersion: '2010-09-09'
Transform: 'AWS::Serverless-2016-10-31'
Description: CloudFormation template for Flink POC - Application with IAM role

Parameters:
  ApplicationName:
    Type: String
    Default: flink-sample-poc
    Description: Name of the Flink application

  S3BucketName:
    Type: String
    Description: S3 bucket name where the JAR file is uploaded

  S3JarKey:
    Type: String
    Default: flink-apps/flink-sample-app-1.0-SNAPSHOT.jar
    Description: S3 key path to the JAR file

Resources:

  # ============================================
  # IAM Role (using working pattern with PermissionsBoundary)
  # ============================================
  FlinkServiceRole:
    Type: "AWS::IAM::Role"
    Properties:
      RoleName:
        'Fn::Sub': 'svc-flink-poc-role'
      Policies:
        - PolicyName:
            'Fn::Sub': 'flink-poc-policy'
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Resource: "*"
                Action:
                  - kinesisanalytics:*
                Effect: "Allow"
              - Resource: "*"
                Action:
                  - kinesis:*
                Effect: "Allow"
              - Resource: "*"
                Action:
                  - logs:*
                Effect: "Allow"
              - Resource: "*"
                Action:
                  - cloudwatch:*
                Effect: "Allow"
              - Resource: "*"
                Action:
                  - s3:GetObject
                  - s3:GetObjectVersion
                  - s3:ListBucket
                Effect: "Allow"
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Action: "sts:AssumeRole"
            Effect: "Allow"
            Principal:
              Service: "kinesisanalytics.amazonaws.com"
      PermissionsBoundary:
        'Fn::Sub': 'arn:aws:iam::${AWS::AccountId}:policy/core-ServiceRolePermissionsBoundary'

  # ============================================
  # CloudWatch Log Group
  # ============================================
  FlinkLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub '/aws/kinesis-analytics/${ApplicationName}'
      RetentionInDays: 7

  FlinkLogStream:
    Type: AWS::Logs::LogStream
    DependsOn: FlinkLogGroup
    Properties:
      LogGroupName: !Sub '/aws/kinesis-analytics/${ApplicationName}'
      LogStreamName: 'flink-app-log-stream'

  # ============================================
  # Managed Flink Application
  # ============================================
  FlinkApplication:
    Type: AWS::KinesisAnalyticsV2::Application
    DependsOn:
      - FlinkServiceRole
      - FlinkLogStream
    Properties:
      ApplicationName: !Ref ApplicationName
      RuntimeEnvironment: FLINK-1_18
      ServiceExecutionRole: !GetAtt FlinkServiceRole.Arn
      ApplicationConfiguration:
        ApplicationCodeConfiguration:
          CodeContent:
            S3ContentLocation:
              BucketARN: !Sub 'arn:aws:s3:::${S3BucketName}'
              FileKey: !Ref S3JarKey
          CodeContentType: ZIPFILE
        EnvironmentProperties:
          PropertyGroups:
            - PropertyGroupId: FlinkApplicationProperties
              PropertyMap:
                environment: poc
        FlinkApplicationConfiguration:
          ParallelismConfiguration:
            ConfigurationType: CUSTOM
            Parallelism: 1
            ParallelismPerKPU: 1
            AutoScalingEnabled: false
          CheckpointConfiguration:
            ConfigurationType: CUSTOM
            CheckpointingEnabled: true
            CheckpointInterval: 60000
            MinPauseBetweenCheckpoints: 5000
          MonitoringConfiguration:
            ConfigurationType: CUSTOM
            MetricsLevel: APPLICATION
            LogLevel: INFO

  # ============================================
  # CloudWatch Logging for Flink App
  # ============================================
  FlinkAppLogging:
    Type: AWS::KinesisAnalyticsV2::ApplicationCloudWatchLoggingOption
    DependsOn: FlinkApplication
    Properties:
      ApplicationName: !Ref ApplicationName
      CloudWatchLoggingOption:
        LogStreamARN: !Sub 'arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/kinesis-analytics/${ApplicationName}:log-stream:flink-app-log-stream'

Outputs:
  FlinkRoleArn:
    Value: !GetAtt FlinkServiceRole.Arn
    Description: ARN of the Flink service role

  ApplicationName:
    Description: Flink Application Name
    Value: !Ref ApplicationName

  LogGroupName:
    Description: CloudWatch Log Group
    Value: !Sub '/aws/kinesis-analytics/${ApplicationName}'
